{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7417,"status":"ok","timestamp":1726969276510,"user":{"displayName":"董学鑫","userId":"01566955359125753091"},"user_tz":-480},"id":"iR7clGC3bgW9","outputId":"f9b40549-430e-490b-903f-2ad26e3011d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    workspace = '/content/drive/MyDrive/Colab Notebooks'\n","except:\n","    workspace = '.'\n","# !pip install torch==1.11.0 torchvision==0.12.0 torchaudio==0.12.0\n","# %pip install torch==1.12.0 torchvision==0.13.0 torchaudio==0.12.0\n","# %pip install -U opencv-python\n","# %pip install -U opencv-contrib-python"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1187,"status":"ok","timestamp":1726969300875,"user":{"displayName":"董学鑫","userId":"01566955359125753091"},"user_tz":-480},"id":"Rnpd3tzuZYjU","outputId":"c82639e4-ce91-4cc3-b132-e85c8f2bbf2b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Classes : ['black', 'blue', 'brown', 'green', 'white', 'red', 'dress', 'pants', 'shorts', 'shoes', 'shirt']\n"]}],"source":["import json\n","import os\n","root = os.path.join(workspace, \"clothes\")\n","meta_path = os.path.join(root, \"meta.json\")\n","meta = json.load(open(meta_path,'r'))\n","\n","classes = meta['classes']\n","print(f\"Classes : {classes}\")"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":384,"status":"ok","timestamp":1726969317071,"user":{"displayName":"董学鑫","userId":"01566955359125753091"},"user_tz":-480},"id":"Hnv048yZgxXN"},"outputs":[],"source":["import os\n","\n","def list_dir_in_directory(directory):\n","  dirs = os.listdir(directory)\n","  d_list = [d for d in dirs if os.path.isdir(os.path.join(directory, d))]\n","  return d_list\n","\n","d_list = list_dir_in_directory(root)\n","img_sets = {}\n","\n","for d in d_list:\n","  img_sets[d] = []\n","\n","\n","images_info = meta['images']\n","for i, img_info in enumerate(images_info):\n","  # path = img_info['path']\n","  cls = img_info['class']\n","  # label = img_info['label']\n","\n","  cls = cls[0] + \"_\" + cls[1]\n","  img_sets[cls].append(i) # 往对应的类别list中，添加(在整个images_info素材集中的)下标\n","\n","\n","import random\n","# 从每个类中随机挑选20个元素作为样本(训练+测试)\n","for cls in img_sets.keys():\n","  temp = random.sample(img_sets[cls], 20)\n","  img_sets[cls].clear()\n","  img_sets[cls] = temp\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":21551,"status":"ok","timestamp":1726969498458,"user":{"displayName":"董学鑫","userId":"01566955359125753091"},"user_tz":-480},"id":"TnuhnsFDpDbs"},"outputs":[],"source":["import os\n","import cv2\n","\n","class Sample:\n","  def __init__(self, img=None, classPair=None, labelList=None, feat=None) -> None:\n","      # self.path = path\n","      self.img = img\n","      self.classColor = classPair[0]\n","      self.classCos = classPair[1]\n","\n","      self.labelColor = labelList[:6]\n","      self.labelCos = labelList[6:]\n","      self.feat = feat\n","      self.pred = None\n","\n","samples = {'train': [], 'val': []}\n","\n","# 从挑选好的样本集中(img_sets)，每类前17个样本用于训练，后3个用于测试\n","for cls in img_sets.keys():\n","  smp_list = img_sets[cls]\n","  for i, idx in enumerate(smp_list):\n","    img_info = images_info[idx]\n","\n","    fpath = os.path.join(root, img_info['path'])\n","    if not os.path.isfile(fpath):\n","      raise ValueError('%s not found' % fpath)\n","    else:\n","      img = cv2.imread(fpath, cv2.IMREAD_COLOR)[..., ::-1] # BGR to RGB\n","      if len(samples['train']) == 0 and len(samples['val'])==0:\n","        H, W, C = img.shape\n","      else:\n","        cv2.resize(img, (W, H))\n","\n","      if i < 17:\n","        samples['train'].append(Sample(img=img, classPair=img_info['class'], labelList=img_info['label']))\n","      else:\n","        samples['val'].append(Sample(img=img, classPair=img_info['class'], labelList=img_info['label']))\n","\n","# print(samples)\n","# print(samples['train'][0].__dict__)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":390,"status":"ok","timestamp":1726970188369,"user":{"displayName":"董学鑫","userId":"01566955359125753091"},"user_tz":-480},"id":"XwsYl4E_0WCr","outputId":"5ed66459-4130-48cd-ac0b-288bc4e09bd4"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([408])\n","torch.Size([408])\n"]}],"source":["import torch\n","\n","color_label = [sample.labelColor for sample in samples['train']]\n","cos_label = [sample.labelCos for sample in samples['train']]\n","\n","# 将独热向量转换为类别索引\n","y_color_train = torch.argmax(torch.tensor(color_label), dim=1).to(torch.long)\n","y_cos_train = torch.argmax(torch.tensor(cos_label), dim=1).to(torch.long)\n","\n","# print(y_color_train)\n","# print(y_cos_train)\n","print(y_color_train.shape)\n","print(y_cos_train.shape)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":6863,"status":"ok","timestamp":1726969544792,"user":{"displayName":"董学鑫","userId":"01566955359125753091"},"user_tz":-480},"id":"TJ1LMgBUg2fA"},"outputs":[],"source":["import os\n","import torch.nn as nn\n","import torch\n","import torchvision.transforms as transforms\n","from PIL import Image\n","from matplotlib import pyplot as plt\n","import torchvision.models as models\n","\n","norm_mean = [0.485, 0.456, 0.406]\n","norm_std = [0.229, 0.224, 0.225]\n","\n","inference_transform = transforms.Compose([\n","  transforms.Resize((256, 256)),\n","  transforms.ToTensor(),\n","  transforms.Normalize(norm_mean, norm_std),\n","])\n","\n","def img_transform(img_rgb, transform=None):\n","  \"\"\"\n","  transform images\n","  :param img_rgb: PIL Image\n","  :param transform: torchvision.transform\n","  :return: tensor\n","  \"\"\"\n","\n","  if transform is None:\n","    raise ValueError(\"there is no transform\")\n","\n","  img_t = transform(Image.fromarray(img_rgb))\n","  return img_t\n","\n","# 加载数据\n","train_imgs = [img_transform(sample.img, inference_transform) for sample in samples['train']]\n","train_imgs = torch.stack(train_imgs, dim=0)\n","\n","\n","test_imgs = [img_transform(sample.img, inference_transform) for sample in samples['val']]\n","test_imgs = torch.stack(test_imgs, dim=0)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2407,"status":"ok","timestamp":1726969573960,"user":{"displayName":"董学鑫","userId":"01566955359125753091"},"user_tz":-480},"id":"Fv8X7jlrY6Dw","outputId":"0637c539-78cb-4008-d2ec-a2711336f6ef"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 85.3MB/s]\n"]}],"source":["import torchvision.models as models\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from collections import OrderedDict\n","\n","\n","# 设备\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","# 多任务学习框架\n","class Net(nn.Module):\n","  def __init__(self, num_color_classes, num_cos_classes):\n","      super().__init__()\n","      self.net = models.resnet18(pretrained=True) # 使用在ImageNet上预训练权重的ResNet18\n","      self.n_features = self.net.fc.in_features  # 得到最后一层的输入特征个数\n","      self.net.fc = nn.Identity() # 将最后一层替换，不做任何操作\n","\n","      self.net.fc1 = nn.Sequential(OrderedDict(\n","          [('linear', nn.Linear(self.n_features,self.n_features)),\n","          ('relu1', nn.ReLU()),\n","          ('final', nn.Linear(self.n_features, num_color_classes))])) # 根据衣物颜色进行分类\n","\n","      self.net.fc2 = nn.Sequential(OrderedDict(\n","          [('linear', nn.Linear(self.n_features,self.n_features)),\n","          ('relu1', nn.ReLU()),\n","          ('final', nn.Linear(self.n_features, num_cos_classes))]))  # 根据衣物种类进行分类\n","\n","      # 冻结 ResNet 除了最后一层的权重参数\n","      for param in self.net.parameters():\n","          param.requires_grad = False  # 先将所有参数设置为不需要梯度\n","\n","      # 仅允许最后的全连接层（自定义部分）进行训练\n","      for param in self.net.fc1.parameters():\n","          param.requires_grad = True\n","      for param in self.net.fc2.parameters():\n","          param.requires_grad = True\n","\n","\n","  def forward(self, x):\n","      features = self.net(x)\n","      color_head = self.net.fc1(features)\n","      cos_head = self.net.fc2(features)\n","      return color_head, cos_head\n","\n","model = Net(num_color_classes=6, num_cos_classes=5)\n","model.to(device)\n","\n","# 损失设计\n","color_criterion = nn.CrossEntropyLoss()\n","cos_criterion = nn.CrossEntropyLoss()\n","\n","# 优化器\n","optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3364053,"status":"ok","timestamp":1726975946528,"user":{"displayName":"董学鑫","userId":"01566955359125753091"},"user_tz":-480},"id":"3IC7gmYMoFmh","outputId":"19f1ba4a-807c-4c59-9a26-c9d1f6607206"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch[10/100] Color Loss: 0.6639485359191895, Type Loss: 0.3926098644733429, Total Loss: 1.05655837059021\n","Epoch[20/100] Color Loss: 0.21719376742839813, Type Loss: 0.11930090188980103, Total Loss: 0.33649468421936035\n","Epoch[30/100] Color Loss: 0.08084291219711304, Type Loss: 0.04548873007297516, Total Loss: 0.1263316422700882\n","Epoch[40/100] Color Loss: 0.0349988155066967, Type Loss: 0.019477052614092827, Total Loss: 0.05447586625814438\n","Epoch[50/100] Color Loss: 0.018284335732460022, Type Loss: 0.010516917333006859, Total Loss: 0.02880125306546688\n","Epoch[60/100] Color Loss: 0.011568279005587101, Type Loss: 0.006812244653701782, Total Loss: 0.01838052272796631\n","Epoch[70/100] Color Loss: 0.008350650779902935, Type Loss: 0.004965667612850666, Total Loss: 0.013316318392753601\n","Epoch[80/100] Color Loss: 0.006524668075144291, Type Loss: 0.0038963970728218555, Total Loss: 0.010421065613627434\n","Epoch[90/100] Color Loss: 0.005334836430847645, Type Loss: 0.0031968243420124054, Total Loss: 0.00853166077286005\n","Epoch[100/100] Color Loss: 0.004486015532165766, Type Loss: 0.0026939052622765303, Total Loss: 0.007179920561611652\n"]}],"source":["import torch.nn as nn\n","import torch\n","from torch.autograd import Variable\n","\n","model.train()\n","\n","# 训练\n","num_epochs = 100\n","for epoch in range(num_epochs):\n","  if torch.cuda.is_available():\n","    inputs = Variable(train_imgs).cuda()\n","    color_target = Variable(y_color_train).cuda()\n","    cos_target = Variable(y_cos_train).cuda()\n","  else:\n","    inputs = Variable(train_imgs)\n","    color_target = Variable(y_color_train)\n","    cos_target = Variable(y_cos_train)\n","\n","\n","  # forward\n","  color_out, cos_out = model(inputs)\n","  loss_color = color_criterion(color_out, color_target)\n","  loss_cos = cos_criterion(cos_out, cos_target)\n","\n","  # total loss\n","  total_loss = loss_color + loss_cos\n","\n","  # backward\n","  optimizer.zero_grad()\n","  total_loss.backward()\n","  optimizer.step()\n","\n","  if (epoch+1) % 10 == 0:\n","    print(f'Epoch[{epoch+1}/{num_epochs}] Color Loss: {loss_color.item()}, Type Loss: {loss_cos.item()}, Total Loss: {total_loss.item()}')"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16155,"status":"ok","timestamp":1726979484973,"user":{"displayName":"董学鑫","userId":"01566955359125753091"},"user_tz":-480},"id":"RPOzGa_0y7ol","outputId":"6f2e3d7a-7bc9-4277-b5be-a15a3d3978b9"},"outputs":[{"name":"stdout","output_type":"stream","text":["F1-score for color classification: 0.8897808321946253\n","F1-score for type classification: 0.944295900178253\n"]}],"source":["import numpy as np\n","import torch\n","from sklearn.metrics import f1_score\n","\n","# 测试数据集\n","y_color_test = np.array([sample.labelColor for sample in samples['val']])\n","y_color_test = np.argmax(y_color_test, axis=1)\n","y_cos_test = np.array([sample.labelCos for sample in samples['val']])\n","y_cos_test = np.argmax(y_cos_test, axis=1)\n","\n","# 在训练完成后，使用模型进行预测\n","model.eval()\n","with torch.no_grad():\n","  outputs_color, outputs_cos = model(test_imgs)\n","  predicted_color = torch.sigmoid(outputs_color).cpu().numpy()\n","  predicted_cos = torch.sigmoid(outputs_cos).cpu().numpy()\n","\n","  # 基于预测结果计算F1-score\n","  y_color_pred = np.argmax(predicted_color, axis=1)\n","  y_cos_pred = np.argmax(predicted_cos, axis=1)\n","\n","  f1_color = f1_score(y_color_test, y_color_pred, average='weighted')\n","  f1_cos = f1_score(y_cos_test, y_cos_pred, average='weighted')\n","\n","  print(f'F1-score for color classification: {f1_color}')\n","  print(f'F1-score for type classification: {f1_cos}')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO/xxLFEIUQkKx9i/4CZdXM","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
