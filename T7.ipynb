{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7417,"status":"ok","timestamp":1726969276510,"user":{"displayName":"董学鑫","userId":"01566955359125753091"},"user_tz":-480},"id":"iR7clGC3bgW9","outputId":"f9b40549-430e-490b-903f-2ad26e3011d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    workspace = '/content/drive/MyDrive/Colab Notebooks'\n","except:\n","    workspace = '.'\n","# !pip install torch==1.11.0 torchvision==0.12.0 torchaudio==0.12.0\n","# %pip install torch==1.12.0 torchvision==0.13.0 torchaudio==0.12.0\n","# %pip install -U opencv-python\n","# %pip install -U opencv-contrib-python"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iFz_Pqn_cu6Q"},"outputs":[],"source":["# load the images\n","import os\n","import csv\n","import cv2\n","import numpy as np\n","from sklearn import datasets\n","from pprint import pprint\n","from collections import namedtuple\n","from matplotlib import pyplot as plt\n","from skimage.feature import hog\n","from sklearn.linear_model import LinearRegression\n","from sklearn.pipeline import make_pipeline\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.preprocessing import StandardScaler\n","\n","root = os.path.join(workspace, 'Figures_T7')\n","label_path = os.path.join(root, 'label.csv')\n","\n","\n","\n","def labels2strs(labels: list) -> list:\n","    # Max length of each column\n","    lengths = np.max([[len(j) for j in i] for i in labels], axis=0)\n","    # Output format\n","    format_str = ' '.join(['{:^%ds}'%length for length in lengths])\n","    seps = ' '.join(['-'*length for length in lengths])\n","    contents = [format_str.format(*row) for row in labels]\n","    contents.insert(1, seps)\n","    return contents\n","\n","class Sample:\n","    def __init__(self, idx=0, fname='', img=None, feat=None, label=None):\n","        self.idx = idx\n","        self.fname = fname\n","        self.img = img\n","        self.feat = feat\n","        self.label = label\n","        self.pred = None\n","\n","if os.path.exists(label_path):\n","    with open(label_path) as f:\n","        flabels = list(csv.reader(f))\n","    print(*labels2strs(flabels), sep='\\n')\n","else:\n","    raise ValueError('Invalid label file path [%s]'%label_path)\n","\n","\n","samples = {'train': [], 'val': []}\n","\n","\n","# index 0: heads [ID, filename, label, split]\n","for idx, fname, label, split in flabels[1:]:\n","    idx, label = int(idx), int(label)\n","    if idx % 4 == 0:\n","        plt.figure(figsize=(16, 4))\n","    plt.subplot(1, 4, idx%4+1)\n","    plt.title(f'{fname} in G{label}({split})')\n","\n","    fpath = os.path.join(root, fname)\n","    if not os.path.isfile(fpath):\n","        raise ValueError('%s not found' % fpath)\n","    else:\n","        img = cv2.imread(fpath, cv2.IMREAD_COLOR)[..., ::-1] #BGR to RGB\n","        if idx == 0:\n","          H, W, C = img.shape\n","        else:\n","          img = cv2.resize(img, (W, H))\n","\n","        plt.imshow(img)\n","\n","        samples[split].append(Sample(idx, fname, img, None, label))\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NBdNCi-0e16J"},"outputs":[],"source":["## extract features\n","\n","def get_feat(img):\n","      return gray_histogram(img)\n","    #  return color_histogram(img)\n","\n","def calc_distance(x, y):\n","    return L2_distance(x, y)\n","\n","def gray_histogram(img: np.array, norm: bool = True) -> np.array:\n","    if img.shape[-1] == 3:\n","        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n","    hist = np.array([len(img[img == i]) for i in range(256)])\n","    if norm:\n","        return hist / np.size(img)\n","    return hist\n","\n","def color_histogram(img : np.array, norm : bool = True) -> np.array:\n","    return np.concatenate([gray_histogram(img[..., i], norm=norm) for i in range(3)])\n","\n","\n","def L2_distance(x, y):\n","    return ((x - y) ** 2).sum() ** 0.5\n","\n","def L2_distance_sift(x, y):\n","    dist = ((x[:, None] - y[None, :])**2).sum(axis=-1).min(axis=-1)\n","    dist.sort()\n","    return dist[:15].mean()\n","\n","# 以样本图像的灰度直方图对应的向量作为特征向量\n","for sample in samples['train']:\n","    sample.feat = get_feat(sample.img)\n","\n","for sample in samples['val']:\n","    sample.feat = get_feat(sample.img)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":493,"status":"ok","timestamp":1726367067243,"user":{"displayName":"董学鑫","userId":"01566955359125753091"},"user_tz":-480},"id":"sJc2Scy0fj4j","outputId":"bae791b3-6bde-4cde-edfb-fc90014956a8"},"outputs":[{"name":"stdout","output_type":"stream","text":["(256,)\n"]}],"source":["print(sample.feat.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":497,"status":"ok","timestamp":1726367304834,"user":{"displayName":"董学鑫","userId":"01566955359125753091"},"user_tz":-480},"id":"Tj91Vo_If53_","outputId":"2a2a70b7-6ffb-4a4b-ba8f-19670f6b6c52"},"outputs":[{"name":"stdout","output_type":"stream","text":["2.jpg with label 0 is predicted as 0\n","7.jpg with label 0 is predicted as 1\n","10.jpg with label 1 is predicted as 1\n","11.jpg with label 0 is predicted as 1\n","13.jpg with label 1 is predicted as 1\n"]}],"source":["# use traditional classifier\n","\n","from sklearn.pipeline import make_pipeline\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.preprocessing import StandardScaler\n","\n","train_samples = [sample.feat for sample in samples['train']]\n","train_labels = [sample.label for sample in samples['train']]\n","\n","\n","# StandardScaler() aims to normalize input dataset via (x-mean)/var\n","# SGDClassifier(): max_iter (iteration times); tol is used for early stop; when learning rate is constant, eta0 is seen as learning rate; log loss means logistic regression\n","# make_pipeline: conduct StandardScaler() first, then create classifier\n","classifier = make_pipeline(StandardScaler(), SGDClassifier(max_iter=50000, tol=1e-3, learning_rate='constant', eta0=0.1, loss='log_loss'))\n","\n","\n","# call classifier for training\n","classifier.fit(train_samples, train_labels)\n","\n","\n","test_samples = [sample.feat for sample in samples['val']]\n","test_labels = [sample.label for sample in samples['val']]\n","\n","# call classifier for prediction\n","results = classifier.predict(test_samples)\n","\n","# display the results\n","for sample, result in zip(samples['val'], results):\n","    sample.pred = result\n","    print(sample.fname, 'with label', sample.label, 'is predicted as', sample.pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20906,"status":"ok","timestamp":1726368090486,"user":{"displayName":"董学鑫","userId":"01566955359125753091"},"user_tz":-480},"id":"Cbke7FNOg0-l","outputId":"b6414d1c-cab1-4f4a-a9a6-7c4ac4a196cd"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-8-b99e6e907883>:34: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:204.)\n","  x_train = torch.tensor(train_samples).to(torch.float32)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch[1000/50000], loss: 0.521153\n","Epoch[2000/50000], loss: 0.430351\n","Epoch[3000/50000], loss: 0.373414\n","Epoch[4000/50000], loss: 0.333474\n","Epoch[5000/50000], loss: 0.303141\n","Epoch[6000/50000], loss: 0.278819\n","Epoch[7000/50000], loss: 0.258577\n","Epoch[8000/50000], loss: 0.241290\n","Epoch[9000/50000], loss: 0.226250\n","Epoch[10000/50000], loss: 0.212987\n","Epoch[11000/50000], loss: 0.201169\n","Epoch[12000/50000], loss: 0.190553\n","Epoch[13000/50000], loss: 0.180955\n","Epoch[14000/50000], loss: 0.172230\n","Epoch[15000/50000], loss: 0.164262\n","Epoch[16000/50000], loss: 0.156955\n","Epoch[17000/50000], loss: 0.150233\n","Epoch[18000/50000], loss: 0.144027\n","Epoch[19000/50000], loss: 0.138282\n","Epoch[20000/50000], loss: 0.132951\n","Epoch[21000/50000], loss: 0.127990\n","Epoch[22000/50000], loss: 0.123364\n","Epoch[23000/50000], loss: 0.119041\n","Epoch[24000/50000], loss: 0.114993\n","Epoch[25000/50000], loss: 0.111196\n","Epoch[26000/50000], loss: 0.107628\n","Epoch[27000/50000], loss: 0.104269\n","Epoch[28000/50000], loss: 0.101102\n","Epoch[29000/50000], loss: 0.098112\n","Epoch[30000/50000], loss: 0.095285\n","Epoch[31000/50000], loss: 0.092608\n","Epoch[32000/50000], loss: 0.090070\n","Epoch[33000/50000], loss: 0.087661\n","Epoch[34000/50000], loss: 0.085372\n","Epoch[35000/50000], loss: 0.083194\n","Epoch[36000/50000], loss: 0.081119\n","Epoch[37000/50000], loss: 0.079140\n","Epoch[38000/50000], loss: 0.077252\n","Epoch[39000/50000], loss: 0.075448\n","Epoch[40000/50000], loss: 0.073723\n","Epoch[41000/50000], loss: 0.072072\n","Epoch[42000/50000], loss: 0.070491\n","Epoch[43000/50000], loss: 0.068975\n","Epoch[44000/50000], loss: 0.067520\n","Epoch[45000/50000], loss: 0.066123\n","Epoch[46000/50000], loss: 0.064780\n","Epoch[47000/50000], loss: 0.063489\n","Epoch[48000/50000], loss: 0.062247\n","Epoch[49000/50000], loss: 0.061051\n","Epoch[50000/50000], loss: 0.059898\n","2.jpg with label 0 is predicted as 0\n","7.jpg with label 0 is predicted as 0\n","10.jpg with label 1 is predicted as 1\n","11.jpg with label 0 is predicted as 1\n","13.jpg with label 1 is predicted as 1\n"]}],"source":["from torch.functional import Tensor\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch.optim as optim\n","\n","input_size = len(train_samples[0])\n","output_size = 1\n","learning_rate = 1\n","\n","\n","# To define a neural network class by pytorch, you have to inhert nn.Module class.\n","class SimpleNN(nn.Module):\n","    def __init__(self):\n","        super(SimpleNN, self).__init__()\n","\n","        # input_size corresponds to input feature dimension.\n","        # output_size coressponds to class number.\n","        self.linear = nn.Linear(input_size, output_size)\n","\n","        #Then, we use sigmoid activation function to gain the probability.\n","        # when probability is larger than 0.5, we treat it as positive 1. Else, we treat it as negative 0.\n","        self.sigmoid = nn.Sigmoid()\n","\n","    # forward function is inherted from parent's class. x denotes the input feature.\n","    def forward(self, x):\n","        y_pred = self.linear(x)\n","        y_pred = self.sigmoid(y_pred)\n","        return y_pred\n","\n","\n","x_train = torch.tensor(train_samples).to(torch.float32)\n","y_train = torch.tensor(train_labels).reshape(-1, 1).to(torch.float32)\n","x_test = torch.tensor(test_samples).to(torch.float32)\n","\n","# create model\n","model = SimpleNN()\n","\n","# create loss function. BCE is binary cross entropy loss\n","criterion = nn.BCELoss()\n","\n","# create optimizer. 1st parameter: the parameters will be optimized; 2nd: learning rate\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","\n","# training\n","# set training flag\n","model.train()\n","num_epochs = 50000\n","for epoch in range(num_epochs):\n","    if torch.cuda.is_available():\n","        inputs = Variable(x_train).cuda()\n","        target = Variable(y_train).cuda()\n","    else:\n","        inputs = Variable(x_train)\n","        target = Variable(y_train)\n","\n","    # forward() function\n","    out = model(inputs)\n","\n","    # calculate loss\n","    loss = criterion(out, target)\n","\n","    # clear gradient\n","    optimizer.zero_grad()\n","\n","    # backward propagation\n","    loss.backward()\n","\n","    # Updating parameters via SGD\n","    optimizer.step()\n","\n","    if (epoch+1) % 1000 == 0:\n","        print('Epoch[{}/{}], loss: {:.6f}'\n","              .format(epoch+1, num_epochs, loss.item()))\n","\n","# testing\n","model.eval()\n","results = model(Variable(x_test))\n","\n","# display the results\n","for sample, result in zip(samples['val'], results):\n","    sample.pred = 1 if result > 0.5 else 0\n","    print(sample.fname, 'with label', sample.label, 'is predicted as', sample.pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":86935,"status":"ok","timestamp":1726369299603,"user":{"displayName":"董学鑫","userId":"01566955359125753091"},"user_tz":-480},"id":"gW6kqIebjvZg","outputId":"1ba14fa7-0b2a-4736-b577-953de13d5248"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch[1000/50000], loss: 0.668511\n","Epoch[2000/50000], loss: 0.364247\n","Epoch[3000/50000], loss: 0.014159\n","Epoch[4000/50000], loss: 0.004353\n","Epoch[5000/50000], loss: 0.002321\n","Epoch[6000/50000], loss: 0.001524\n","Epoch[7000/50000], loss: 0.001114\n","Epoch[8000/50000], loss: 0.000867\n","Epoch[9000/50000], loss: 0.000704\n","Epoch[10000/50000], loss: 0.000589\n","Epoch[11000/50000], loss: 0.000504\n","Epoch[12000/50000], loss: 0.000439\n","Epoch[13000/50000], loss: 0.000388\n","Epoch[14000/50000], loss: 0.000347\n","Epoch[15000/50000], loss: 0.000313\n","Epoch[16000/50000], loss: 0.000285\n","Epoch[17000/50000], loss: 0.000261\n","Epoch[18000/50000], loss: 0.000240\n","Epoch[19000/50000], loss: 0.000222\n","Epoch[20000/50000], loss: 0.000207\n","Epoch[21000/50000], loss: 0.000193\n","Epoch[22000/50000], loss: 0.000181\n","Epoch[23000/50000], loss: 0.000171\n","Epoch[24000/50000], loss: 0.000161\n","Epoch[25000/50000], loss: 0.000152\n","Epoch[26000/50000], loss: 0.000145\n","Epoch[27000/50000], loss: 0.000138\n","Epoch[28000/50000], loss: 0.000131\n","Epoch[29000/50000], loss: 0.000125\n","Epoch[30000/50000], loss: 0.000120\n","Epoch[31000/50000], loss: 0.000115\n","Epoch[32000/50000], loss: 0.000110\n","Epoch[33000/50000], loss: 0.000106\n","Epoch[34000/50000], loss: 0.000102\n","Epoch[35000/50000], loss: 0.000098\n","Epoch[36000/50000], loss: 0.000094\n","Epoch[37000/50000], loss: 0.000091\n","Epoch[38000/50000], loss: 0.000088\n","Epoch[39000/50000], loss: 0.000085\n","Epoch[40000/50000], loss: 0.000082\n","Epoch[41000/50000], loss: 0.000080\n","Epoch[42000/50000], loss: 0.000077\n","Epoch[43000/50000], loss: 0.000075\n","Epoch[44000/50000], loss: 0.000073\n","Epoch[45000/50000], loss: 0.000071\n","Epoch[46000/50000], loss: 0.000069\n","Epoch[47000/50000], loss: 0.000067\n","Epoch[48000/50000], loss: 0.000065\n","Epoch[49000/50000], loss: 0.000064\n","Epoch[50000/50000], loss: 0.000062\n","2.jpg with label 0 is predicted as 0\n","7.jpg with label 0 is predicted as 0\n","10.jpg with label 1 is predicted as 1\n","11.jpg with label 0 is predicted as 1\n","13.jpg with label 1 is predicted as 1\n"]}],"source":["hidden_size = input_size * 2\n","\n","# see if a 3-layer NN helps\n","# display the results\n","class SimpleNN_3layer(nn.Module):\n","    def __init__(self):\n","        super(SimpleNN_3layer, self).__init__()\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        self.fc2 = nn.Linear(hidden_size, hidden_size)\n","        self.fc3 = nn.Linear(hidden_size, output_size)\n","\n","        self.relu = nn.ReLU()\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        x = self.relu(self.fc1(x))\n","        x = self.relu(self.fc2(x))\n","        y_pred = self.sigmoid(self.fc3(x))\n","        return y_pred\n","\n","model = SimpleNN_3layer()\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.1) # 原来1.0的学习率太大\n","\n","# training and testing\n","model.train()\n","num_epochs = 50000\n","for epoch in range(num_epochs):\n","    if torch.cuda.is_available():\n","        inputs = Variable(x_train).cuda()\n","        target = Variable(y_train).cuda()\n","    else:\n","        inputs = Variable(x_train)\n","        target = Variable(y_train)\n","\n","    # forward\n","    out = model(inputs)\n","    loss = criterion(out, target)\n","\n","    # backward\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if (epoch+1) % 1000 == 0:\n","        print('Epoch[{}/{}], loss: {:.6f}'\n","              .format(epoch+1, num_epochs, loss.item()))\n","\n","model.eval()\n","results = model(Variable(x_test))\n","\n","# display the results\n","for sample, result in zip(samples['val'], results):\n","    sample.pred = 1 if result > 0.5 else 0\n","    print(sample.fname, 'with label', sample.label, 'is predicted as', sample.pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":783678,"status":"ok","timestamp":1726374540709,"user":{"displayName":"董学鑫","userId":"01566955359125753091"},"user_tz":-480},"id":"mn_d50wrooKS","outputId":"6be6cce6-fc19-4ee4-c673-d27966dad29b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch[20/200], loss: 0.025402\n","Epoch[40/200], loss: 0.004448\n","Epoch[60/200], loss: 0.001825\n","Epoch[80/200], loss: 0.001019\n","Epoch[100/200], loss: 0.000634\n","Epoch[120/200], loss: 0.000418\n","Epoch[140/200], loss: 0.000286\n","Epoch[160/200], loss: 0.000200\n","Epoch[180/200], loss: 0.000143\n","Epoch[200/200], loss: 0.000103\n","2.jpg with label 0 is predicted as 0\n","7.jpg with label 0 is predicted as 0\n","10.jpg with label 1 is predicted as 1\n","11.jpg with label 0 is predicted as 0\n","13.jpg with label 1 is predicted as 1\n"]}],"source":["# load pre-trained ResNet for feature extraction\n","# add a few FC for traning (fix the weights of ResNet)\n","# test and display the results\n","import os\n","import time\n","import torch.nn as nn\n","import torch\n","import torchvision.transforms as transforms\n","from PIL import Image\n","from matplotlib import pyplot as plt\n","import torchvision.models as models\n","try:\n","    from torch.hub import load_state_dict_from_url\n","except ImportError:\n","    from torch.utils.model_zoo import load_url as load_state_dict_from_url\n","\n","# define device, gpu or cpu\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","# dataset construction\n","# This time we don't have to extract the features. Deep neural networks usually take the images as the input directly.\n","\n","norm_mean = [0.485, 0.456, 0.406]\n","norm_std = [0.229, 0.224, 0.225]\n","\n","inference_transform = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.ToTensor(),\n","    transforms.Normalize(norm_mean, norm_std),\n","])\n","def img_transform(img_rgb, transform=None):\n","    \"\"\"\n","    transform images\n","    :param img_rgb: PIL Image\n","    :param transform: torchvision.transform\n","    :return: tensor\n","    \"\"\"\n","\n","    if transform is None:\n","        raise ValueError(\"there is no transform\")\n","\n","    img_t = transform(Image.fromarray(img_rgb))\n","    return img_t\n","\n","# load data\n","train_imgs = [img_transform(sample.img, inference_transform) for sample in samples['train']]\n","train_imgs = torch.stack(train_imgs, dim=0)\n","\n","\n","test_imgs = [img_transform(sample.img, inference_transform) for sample in samples['val']]\n","test_imgs = torch.stack(test_imgs, dim=0)\n","\n","\n","# define a classifier following the network\n","class classification_head(nn.Module):\n","\tdef __init__(self,in_ch,num_classes):\n","\t\tsuper(classification_head,self).__init__()\n","\t\tself.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n","\t\tself.fc = nn.Linear(in_ch,num_classes)\n","\n","\tdef forward(self, x):\n","\t\tx = self.avgpool(x)\n","\t\tx = torch.flatten(x, 1)\n","\t\tx = self.fc(x)\n","\t\treturn x\n","\n","\n","# define ResNet model.\n","# a simple tips here: you can follow the execute sequence in forward() to understand what a network is.\n","# For original ResNet, its final layer will output 1000 class number. Here, we change it for our task.\n","class Net(nn.Module):\n","\tdef __init__(self, num_class,pretrained=True):\n","\t\tsuper(Net,self).__init__()\n","\t\tmodel = models.resnet50(pretrained=pretrained)\n","\t\tself.backbone =  nn.Sequential(*list(model.children())[:-2]) #remove the last Avgpool and Fully Connected Layer\n","\t\tself.classification_head = classification_head(2048, num_class)\n","\n","\tdef forward(self,x):\n","\t\tx = self.backbone(x)\n","\t\toutput = self.classification_head(x)\n","\t\treturn output\n","\n","\n","# creat a model\n","model = Net(1)\n","\n","# fix the weights of ResNet except the last layer. This is because the training set is small.\n","for p in model.backbone.parameters():\n","  p.requires_grad = False\n","\n","model.to(device)\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n","\n","model.train()\n","\n","# training\n","num_epochs = 200\n","for epoch in range(num_epochs):\n","    if torch.cuda.is_available():\n","        inputs = Variable(train_imgs).cuda()\n","        target = Variable(y_train).cuda()\n","    else:\n","        inputs = Variable(train_imgs)\n","        target = Variable(y_train)\n","\n","    # forward\n","    out = model(inputs)\n","    loss = criterion(out, target)\n","\n","    # backward\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if (epoch+1) % 20 == 0:\n","        print('Epoch[{}/{}], loss: {:.6f}'\n","              .format(epoch+1, num_epochs, loss.item()))\n","\n","#testing\n","model.eval()\n","results = model(Variable(test_imgs))\n","\n","# display the results\n","for sample, result in zip(samples['val'], results):\n","    sample.pred = 1 if result > 0.5 else 0\n","    print(sample.fname, 'with label', sample.label, 'is predicted as', sample.pred)"]},{"cell_type":"markdown","metadata":{"id":"ilqjZUbnpngM"},"source":["\n","```\n","以下内容为多标签分类任务的代码\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11961,"status":"ok","timestamp":1726886797365,"user":{"displayName":"董学鑫","userId":"01566955359125753091"},"user_tz":-480},"id":"BUOio6S16MxD","outputId":"336543a1-e660-4209-8322-e8e3f96daa85"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.20252343 0.02968957 0.03978538 ... 0.04491646 0.0716226  0.03410894]\n"]}],"source":["test = os.path.join(workspace, \"Figures_T7/1.jpg\")\n","import cv2\n","import numpy as np\n","from skimage.feature import hog\n","from matplotlib import pyplot as plt\n","\n","# Extract the feature of images\n","def gray_hist(img : np.array, norm : bool = True) -> np.array:\n","  if img.shape[-1] == 3:\n","    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n","\n","  hist = np.array([len(img[img==i]) for i in range(256)])\n","  if norm:\n","    hist = hist / np.size(img)\n","  return hist\n","\n","def color_hist(img : np.array, norm : bool = True) -> np.array:\n","  return np.array([gray_hist(img[..., i], norm) for i in range(3)])\n","\n","\n","def get_feat(img):\n","  return hog(img, channel_axis=-1)\n","\n","img = cv2.imread(test)[..., ::-1] # To BGR channel\n","print(get_feat(img))"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1187,"status":"ok","timestamp":1726969300875,"user":{"displayName":"董学鑫","userId":"01566955359125753091"},"user_tz":-480},"id":"Rnpd3tzuZYjU","outputId":"c82639e4-ce91-4cc3-b132-e85c8f2bbf2b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Classes : ['black', 'blue', 'brown', 'green', 'white', 'red', 'dress', 'pants', 'shorts', 'shoes', 'shirt']\n"]}],"source":["import json\n","import os\n","root = os.path.join(workspace, \"clothes\")\n","meta_path = os.path.join(root, \"meta.json\")\n","meta = json.load(open(meta_path,'r'))\n","\n","classes = meta['classes']\n","print(f\"Classes : {classes}\")"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":384,"status":"ok","timestamp":1726969317071,"user":{"displayName":"董学鑫","userId":"01566955359125753091"},"user_tz":-480},"id":"Hnv048yZgxXN"},"outputs":[],"source":["import os\n","\n","def list_dir_in_directory(directory):\n","  dirs = os.listdir(directory)\n","  d_list = [d for d in dirs if os.path.isdir(os.path.join(directory, d))]\n","  return d_list\n","\n","d_list = list_dir_in_directory(root)\n","img_sets = {}\n","\n","for d in d_list:\n","  img_sets[d] = []\n","\n","\n","images_info = meta['images']\n","for i, img_info in enumerate(images_info):\n","  # path = img_info['path']\n","  cls = img_info['class']\n","  # label = img_info['label']\n","\n","  cls = cls[0] + \"_\" + cls[1]\n","  img_sets[cls].append(i) # 往对应的类别list中，添加(在整个images_info素材集中的)下标\n","\n","\n","import random\n","# 从每个类中随机挑选20个元素作为样本(训练+测试)\n","for cls in img_sets.keys():\n","  temp = random.sample(img_sets[cls], 20)\n","  img_sets[cls].clear()\n","  img_sets[cls] = temp\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":388,"status":"ok","timestamp":1726969335240,"user":{"displayName":"董学鑫","userId":"01566955359125753091"},"user_tz":-480},"id":"-tR77tIRlqME","outputId":"e9021dab-edc4-442d-8482-35968606a303"},"outputs":[{"name":"stdout","output_type":"stream","text":["green_shirt : 20\n","white_pants : 20\n","green_shoes : 20\n","red_dress : 20\n","white_shoes : 20\n","white_shorts : 20\n","red_shoes : 20\n","white_dress : 20\n","red_pants : 20\n","green_shorts : 20\n","blue_dress : 20\n","green_pants : 20\n","blue_pants : 20\n","brown_pants : 20\n","black_shorts : 20\n","blue_shoes : 20\n","blue_shorts : 20\n","brown_shorts : 20\n","blue_shirt : 20\n","brown_shoes : 20\n","black_pants : 20\n","black_dress : 20\n","black_shoes : 20\n","black_shirt : 20\n"]}],"source":["# print(img_sets)\n","for cls in img_sets.keys():\n","  lens = len(img_sets[cls])\n","  print(f\"{cls} : {lens}\")"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":21551,"status":"ok","timestamp":1726969498458,"user":{"displayName":"董学鑫","userId":"01566955359125753091"},"user_tz":-480},"id":"TnuhnsFDpDbs"},"outputs":[],"source":["import os\n","import cv2\n","\n","class Sample:\n","  def __init__(self, img=None, classPair=None, labelList=None, feat=None) -> None:\n","      # self.path = path\n","      self.img = img\n","      self.classColor = classPair[0]\n","      self.classCos = classPair[1]\n","\n","      self.labelColor = labelList[:6]\n","      self.labelCos = labelList[6:]\n","      self.feat = feat\n","      self.pred = None\n","\n","samples = {'train': [], 'val': []}\n","\n","# 从挑选好的样本集中(img_sets)，每类前17个样本用于训练，后3个用于测试\n","for cls in img_sets.keys():\n","  smp_list = img_sets[cls]\n","  for i, idx in enumerate(smp_list):\n","    img_info = images_info[idx]\n","\n","    fpath = os.path.join(root, img_info['path'])\n","    if not os.path.isfile(fpath):\n","      raise ValueError('%s not found' % fpath)\n","    else:\n","      img = cv2.imread(fpath, cv2.IMREAD_COLOR)[..., ::-1] # BGR to RGB\n","      if len(samples['train']) == 0 and len(samples['val'])==0:\n","        H, W, C = img.shape\n","      else:\n","        cv2.resize(img, (W, H))\n","\n","      if i < 17:\n","        samples['train'].append(Sample(img=img, classPair=img_info['class'], labelList=img_info['label']))\n","      else:\n","        samples['val'].append(Sample(img=img, classPair=img_info['class'], labelList=img_info['label']))\n","\n","# print(samples)\n","# print(samples['train'][0].__dict__)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":390,"status":"ok","timestamp":1726970188369,"user":{"displayName":"董学鑫","userId":"01566955359125753091"},"user_tz":-480},"id":"XwsYl4E_0WCr","outputId":"5ed66459-4130-48cd-ac0b-288bc4e09bd4"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([408])\n","torch.Size([408])\n"]}],"source":["import torch\n","\n","color_label = [sample.labelColor for sample in samples['train']]\n","cos_label = [sample.labelCos for sample in samples['train']]\n","\n","# 将独热向量转换为类别索引\n","y_color_train = torch.argmax(torch.tensor(color_label), dim=1).to(torch.long)\n","y_cos_train = torch.argmax(torch.tensor(cos_label), dim=1).to(torch.long)\n","\n","# print(y_color_train)\n","# print(y_cos_train)\n","print(y_color_train.shape)\n","print(y_cos_train.shape)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":6863,"status":"ok","timestamp":1726969544792,"user":{"displayName":"董学鑫","userId":"01566955359125753091"},"user_tz":-480},"id":"TJ1LMgBUg2fA"},"outputs":[],"source":["import os\n","import torch.nn as nn\n","import torch\n","import torchvision.transforms as transforms\n","from PIL import Image\n","from matplotlib import pyplot as plt\n","import torchvision.models as models\n","\n","norm_mean = [0.485, 0.456, 0.406]\n","norm_std = [0.229, 0.224, 0.225]\n","\n","inference_transform = transforms.Compose([\n","  transforms.Resize((256, 256)),\n","  transforms.ToTensor(),\n","  transforms.Normalize(norm_mean, norm_std),\n","])\n","\n","def img_transform(img_rgb, transform=None):\n","  \"\"\"\n","  transform images\n","  :param img_rgb: PIL Image\n","  :param transform: torchvision.transform\n","  :return: tensor\n","  \"\"\"\n","\n","  if transform is None:\n","    raise ValueError(\"there is no transform\")\n","\n","  img_t = transform(Image.fromarray(img_rgb))\n","  return img_t\n","\n","# 加载数据\n","train_imgs = [img_transform(sample.img, inference_transform) for sample in samples['train']]\n","train_imgs = torch.stack(train_imgs, dim=0)\n","\n","\n","test_imgs = [img_transform(sample.img, inference_transform) for sample in samples['val']]\n","test_imgs = torch.stack(test_imgs, dim=0)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2407,"status":"ok","timestamp":1726969573960,"user":{"displayName":"董学鑫","userId":"01566955359125753091"},"user_tz":-480},"id":"Fv8X7jlrY6Dw","outputId":"0637c539-78cb-4008-d2ec-a2711336f6ef"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 85.3MB/s]\n"]}],"source":["import torchvision.models as models\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from collections import OrderedDict\n","\n","\n","# 设备\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","# 多任务学习框架\n","class Net(nn.Module):\n","  def __init__(self, num_color_classes, num_cos_classes):\n","      super().__init__()\n","      self.net = models.resnet18(pretrained=True) # 使用在ImageNet上预训练权重的ResNet18\n","      self.n_features = self.net.fc.in_features  # 得到最后一层的输入特征个数\n","      self.net.fc = nn.Identity() # 将最后一层替换，不做任何操作\n","\n","      self.net.fc1 = nn.Sequential(OrderedDict(\n","          [('linear', nn.Linear(self.n_features,self.n_features)),\n","          ('relu1', nn.ReLU()),\n","          ('final', nn.Linear(self.n_features, num_color_classes))])) # 根据衣物颜色进行分类\n","\n","      self.net.fc2 = nn.Sequential(OrderedDict(\n","          [('linear', nn.Linear(self.n_features,self.n_features)),\n","          ('relu1', nn.ReLU()),\n","          ('final', nn.Linear(self.n_features, num_cos_classes))]))  # 根据衣物种类进行分类\n","\n","      # 冻结 ResNet 除了最后一层的权重参数\n","      for param in self.net.parameters():\n","          param.requires_grad = False  # 先将所有参数设置为不需要梯度\n","\n","      # 仅允许最后的全连接层（自定义部分）进行训练\n","      for param in self.net.fc1.parameters():\n","          param.requires_grad = True\n","      for param in self.net.fc2.parameters():\n","          param.requires_grad = True\n","\n","\n","  def forward(self, x):\n","      features = self.net(x)\n","      color_head = self.net.fc1(features)\n","      cos_head = self.net.fc2(features)\n","      return color_head, cos_head\n","\n","model = Net(num_color_classes=6, num_cos_classes=5)\n","model.to(device)\n","\n","# 损失设计\n","color_criterion = nn.CrossEntropyLoss()\n","cos_criterion = nn.CrossEntropyLoss()\n","\n","# 优化器\n","optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3364053,"status":"ok","timestamp":1726975946528,"user":{"displayName":"董学鑫","userId":"01566955359125753091"},"user_tz":-480},"id":"3IC7gmYMoFmh","outputId":"19f1ba4a-807c-4c59-9a26-c9d1f6607206"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch[10/100] Color Loss: 0.6639485359191895, Type Loss: 0.3926098644733429, Total Loss: 1.05655837059021\n","Epoch[20/100] Color Loss: 0.21719376742839813, Type Loss: 0.11930090188980103, Total Loss: 0.33649468421936035\n","Epoch[30/100] Color Loss: 0.08084291219711304, Type Loss: 0.04548873007297516, Total Loss: 0.1263316422700882\n","Epoch[40/100] Color Loss: 0.0349988155066967, Type Loss: 0.019477052614092827, Total Loss: 0.05447586625814438\n","Epoch[50/100] Color Loss: 0.018284335732460022, Type Loss: 0.010516917333006859, Total Loss: 0.02880125306546688\n","Epoch[60/100] Color Loss: 0.011568279005587101, Type Loss: 0.006812244653701782, Total Loss: 0.01838052272796631\n","Epoch[70/100] Color Loss: 0.008350650779902935, Type Loss: 0.004965667612850666, Total Loss: 0.013316318392753601\n","Epoch[80/100] Color Loss: 0.006524668075144291, Type Loss: 0.0038963970728218555, Total Loss: 0.010421065613627434\n","Epoch[90/100] Color Loss: 0.005334836430847645, Type Loss: 0.0031968243420124054, Total Loss: 0.00853166077286005\n","Epoch[100/100] Color Loss: 0.004486015532165766, Type Loss: 0.0026939052622765303, Total Loss: 0.007179920561611652\n"]}],"source":["import torch.nn as nn\n","import torch\n","from torch.autograd import Variable\n","\n","model.train()\n","\n","# 训练\n","num_epochs = 100\n","for epoch in range(num_epochs):\n","  if torch.cuda.is_available():\n","    inputs = Variable(train_imgs).cuda()\n","    color_target = Variable(y_color_train).cuda()\n","    cos_target = Variable(y_cos_train).cuda()\n","  else:\n","    inputs = Variable(train_imgs)\n","    color_target = Variable(y_color_train)\n","    cos_target = Variable(y_cos_train)\n","\n","\n","  # forward\n","  color_out, cos_out = model(inputs)\n","  loss_color = color_criterion(color_out, color_target)\n","  loss_cos = cos_criterion(cos_out, cos_target)\n","\n","  # total loss\n","  total_loss = loss_color + loss_cos\n","\n","  # backward\n","  optimizer.zero_grad()\n","  total_loss.backward()\n","  optimizer.step()\n","\n","  if (epoch+1) % 10 == 0:\n","    print(f'Epoch[{epoch+1}/{num_epochs}] Color Loss: {loss_color.item()}, Type Loss: {loss_cos.item()}, Total Loss: {total_loss.item()}')"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16155,"status":"ok","timestamp":1726979484973,"user":{"displayName":"董学鑫","userId":"01566955359125753091"},"user_tz":-480},"id":"RPOzGa_0y7ol","outputId":"6f2e3d7a-7bc9-4277-b5be-a15a3d3978b9"},"outputs":[{"name":"stdout","output_type":"stream","text":["F1-score for color classification: 0.8897808321946253\n","F1-score for type classification: 0.944295900178253\n"]}],"source":["import numpy as np\n","import torch\n","from sklearn.metrics import f1_score\n","\n","# 测试数据集\n","y_color_test = np.array([sample.labelColor for sample in samples['val']])\n","y_color_test = np.argmax(y_color_test, axis=1)\n","y_cos_test = np.array([sample.labelCos for sample in samples['val']])\n","y_cos_test = np.argmax(y_cos_test, axis=1)\n","\n","# 在训练完成后，使用模型进行预测\n","model.eval()\n","with torch.no_grad():\n","  outputs_color, outputs_cos = model(test_imgs)\n","  predicted_color = torch.sigmoid(outputs_color).cpu().numpy()\n","  predicted_cos = torch.sigmoid(outputs_cos).cpu().numpy()\n","\n","  # 基于预测结果计算F1-score\n","  y_color_pred = np.argmax(predicted_color, axis=1)\n","  y_cos_pred = np.argmax(predicted_cos, axis=1)\n","\n","  f1_color = f1_score(y_color_test, y_color_pred, average='weighted')\n","  f1_cos = f1_score(y_cos_test, y_cos_pred, average='weighted')\n","\n","  print(f'F1-score for color classification: {f1_color}')\n","  print(f'F1-score for type classification: {f1_cos}')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO/xxLFEIUQkKx9i/4CZdXM","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
